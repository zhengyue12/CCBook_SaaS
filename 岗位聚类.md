#### JobClusterService.java

```java
	public ServiceState process() {/////
		isTaskDone.set(false);
		List<Map<String, Object>> list = new ArrayList<>();
		MongoClient mongo = mongodbstorage.setUp();
		JobCluster cluster = new JobCluster();
		String jsonContext = ReadFile.ReadFile(System.getProperty("user.dir")+"/configuration/job_industry_skills.json");
		JSONObject jsonObject = new JSONObject(jsonContext);
		JSONArray jsonArray = jsonObject.getJSONArray("industry");
		for (int i = 0; i < jsonArray.length(); i++) {
			Map<String, Object> map = new HashMap<>();
			JSONObject industry = jsonArray.getJSONObject(i);
			String[] id = industry.getString("industry-id").split("_");
			map.put("industry-id", id[1]);
			String[] category = industry.getString("category").split(",");
			List<String> cList = new ArrayList<>();
			for (String c : category) {
				cList.add(c);
			}
			map.put("category", cList);
			String[] skills = industry.getString("skills").split(",");
			List<String> sList = new ArrayList<>();
			for (String s : skills) {
				sList.add(s);
			}
			map.put("skills", sList);
			list.add(map);
		}
		for (Map<String, Object> m : list) {
			String id = (String)m.get("industry-id");
			List<String> category = (List<String>)m.get("category");
			for (String c : category) {
				for (int i = 0; i < clusterCount.length; i++) {
					cluster.cluster(id, c, (List<String>)m.get("skills"), clusterCount[i], mongo);
				}
			}
		}
		try {
			new HbaseStatistics().doDataStatistics();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} finally {
			isTaskDone.set(true);
		}
		return ServiceState.STATE_RUNNING;
	}
```



#### HbaseStatistics.java

```java
	private static Properties eduProperties = UtilTools.getConfig(System.getProperty("user.dir") +	"/configuration/job_education.properties");
	private Map<String, String> edus = new HashMap<String, String>();
	public HbaseStatistics() {
        ……
        String[] edu = eduProperties.getProperty("education").split(",");
		for (String e : edu) {
			edus.put(e, e);
		}
    }  //（这里是因为项目是比较老的原因，需要加上以上内容才能正常显示学历相关信息）


    public void countEducationDistribution(String tableName, String mongoTable, 	String family) throws SQLException, IOException {/////
		MongoClient mongoClient = mongodbstorage.setUp();
		// String sql = "select LOCATION,count(1) as count,sum(AMOUNT) from " +
		// tableName
		// + " where ISPERCEPTED = 'no' group by LOCATION order by count desc";
		// ResultSet results = stmt.executeQuery(sql);

		// 建立表的连接
		Table table = connection.getTable(TableName.valueOf(tableName));
		// 创建一个空的Scan实例
		Scan scan1 = new Scan();
		// 可以指定具体的列族列
		scan1.addColumn(Bytes.toBytes(family), Bytes.toBytes("EDUCATION")).addColumn(Bytes.toBytes(family),
				Bytes.toBytes("AMOUNT"));
		scan1.setCaching(60);
		scan1.setMaxResultSize(1 * 1024 * 1024); // 100k （MB1 * 1024 * 1024）
		scan1.setFilter(new PageFilter(1000));

		// 在行上获取遍历器
		ResultScanner scanner1 = table.getScanner(scan1);

		Map map = mongodbstorage.create(mongoTable, "job_education_distribution", mongoClient);// mongodb集合,key,value
		MongoCollection<Document> collection = (MongoCollection<Document>) map.get("collection");
		Document document = (Document) map.get("document");
		SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
		java.util.Date date = new java.util.Date();
		String da = sdf.format(date);
		mongodbstorage.appendString(document, "date", da);
		int[] cu = new int[34];
		int[] nu = new int[34];
		Vector<Document> vec = new Vector<Document>();
		for (Result res : scanner1) {
			String loc = (new String(CellUtil.cloneValue(res.rawCells()[1]))).split("-")[0];
			int total = Integer.parseInt(new String(CellUtil.cloneValue(res.rawCells()[0])));
			int num = 1;
			if (!edus.containsKey(loc)) {
			} else {
				// String prov = jobanalysisreposity.appendProvinceDistribution(document, loc,
				// total, mongoClient);
				String prov = edus.get(loc);
				switch (prov) {
				case "初中":
					cu[0] += total;
					nu[0] += num;
					break;
				case "高中":
					cu[1] += total;
					nu[1] += num;
					break;
				case "中技":
					cu[2] += total;
					nu[2] += num;
					break;
				case "中专":
					cu[3] += total;
					nu[3] += num;
					break;
				case "大专":
					cu[4] += total;
					nu[4] += num;
					break;
				case "本科":
					cu[5] += total;
					nu[5] += num;
					break;
				case "硕士":
					cu[6] += total;
					nu[6] += num;
					break;
				case "博士":
					cu[7] += total;
					nu[7] += num;
					break;
				case "不限":
					cu[8] += total;
					nu[8] += num;
					break;
				}
			}
			logger.info(loc + ":" + total);
		}
		Document[] doc = new Document[9];
		for (int i = 0; i <= 8; i++) {
			doc[i] = new Document();
		}
		mongodbstorage.appendProvince(doc[0], "初中", cu[0], nu[0]);
		mongodbstorage.appendProvince(doc[1], "高中", cu[1], nu[1]);
		mongodbstorage.appendProvince(doc[2], "中技", cu[2], nu[2]);
		mongodbstorage.appendProvince(doc[3], "中专", cu[3], nu[3]);
		mongodbstorage.appendProvince(doc[4], "大专", cu[4], nu[4]);
		mongodbstorage.appendProvince(doc[5], "本科", cu[5], nu[5]);
		mongodbstorage.appendProvince(doc[6], "硕士", cu[6], nu[6]);
		mongodbstorage.appendProvince(doc[7], "博士", cu[7], nu[7]);
		mongodbstorage.appendProvince(doc[8], "不限", cu[8], nu[8]);
	
		for (int i = 0; i <= 8; i++) {
			vec.add(doc[i]);
		}
		mongodbstorage.appendArray(document, "category", vec);
		mongodbstorage.insertOne(collection, document);
	}
```

#### JobCLuster.java

```java
	public List<Integer> kMeans(List<double[]> des1, int cluster) {
		String master = sparkProperties.getProperty("spark_master");
		SparkConf conf = new SparkConf().setMaster(master).setAppName("JobCluster");
		JavaSparkContext jsc = new JavaSparkContext(conf);
		List<Vector> list = new ArrayList<>();
		for (int i = 0; i < des1.size(); i++) {
			Vector vc = Vectors.dense(des1.get(i));
			list.add(vc);
		}
		JavaRDD<Vector> data = jsc.parallelize(list);
		int clusterIteartor = 5000;
		int runs = 300;
		KMeansModel km = KMeans.train(data.rdd(), cluster, clusterIteartor, runs);
		JavaRDD<Integer> kmResult = km.predict(data);
		km.clusterCenters();
		List<Integer> collect = kmResult.collect();
		List<Integer> indexs = new ArrayList<>();
		for (Integer c : collect) {
			indexs.add(c);
		}
		jsc.close();
		return indexs;
	}
```



#### 运行时，注意在JobAnalysisService.java中注释掉不启用的服务

```java
	@Override
	public ServiceState start() {

//		 1. 启动收集服务（虫）
//		Service jobCollector = new JobCollectService(server, this);
//		jobCollector.start();
//		// 2. 启动清洗服务（清洗）
//		Service jobCleaner = new JobCleanService(server, this);
//		jobCleaner.start();
//		// 3. 启动分析服务（聚类）
		Service jobCluster = new JobClusterService(server, this);
		jobCluster.start();
		return ServiceState.STATE_RUNNING;
	}
```



#### 聚类完成后，需要进入xueqing-client项目找到LeanringController类。注释掉相关的代码片段，注释原因可以自行对照MongoDB的数据。

```java
	@RequestMapping("/gwechart")
	@ResponseBody
	public MessageBean getgwEchartsData(String id) {
		Map<String, Object> map = new HashMap<>();
		// 地区分布
		Map<String, Object> echartsObjs1 = jobAnalysisReposity.getMap(mongoClient, id, province);
		map.put("province", echartsObjs1);
		// 薪资
//		Map<String, Object> map1 = jobAnalysisReposity.getSalary(mongoClient, id, salary);
//		map.put("salary", map1);
		// 学历
		List<EchartsObj> echartsObjs2 = jobAnalysisReposity.getEducation(mongoClient, id, education);
		map.put("education", echartsObjs2);
		// 经验
//		List<EchartsObj> echartsObjs3 = jobAnalysisReposity.getExperience(mongoClient, id, experience);
//		map.put("experience", echartsObjs3);
		// 性质
//		Map<String, Object> map2 = jobAnalysisReposity.getNature(mongoClient, id, nature);
//		map.put("nature", map2);
		// 规模
//		Map<String, Object> map3 = jobAnalysisReposity.getScale(mongoClient, id, scale);
//		map.put("scale", map3);
		return new MessageBean(true, "", map);

	}
```

